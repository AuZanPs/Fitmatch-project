-- GEMINI CACHE CLEANUP FUNCTION
-- This function manages the gemini_cache table to prevent unlimited growth

-- First, create a maintenance logs table to track cleanup operations
CREATE TABLE IF NOT EXISTS public.maintenance_logs (
  id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
  operation VARCHAR(50) NOT NULL,
  details TEXT,
  records_affected INTEGER,
  executed_at TIMESTAMPTZ DEFAULT NOW() NOT NULL
);

-- Basic cleanup function: Deletes entries older than specified interval
CREATE OR REPLACE FUNCTION cleanup_old_cache(age_interval TEXT)
RETURNS INTEGER
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = public
AS $$
DECLARE
  deleted_count INTEGER;
BEGIN
  -- Delete entries older than the specified interval
  DELETE FROM public.gemini_cache
  WHERE created_at < NOW() - age_interval::interval
  RETURNING COUNT(*) INTO deleted_count;
  
  -- Log the cleanup operation
  INSERT INTO public.maintenance_logs (
    operation, 
    details, 
    records_affected
  ) 
  VALUES (
    'cache_cleanup',
    format('Deleted cache entries older than %s', age_interval),
    deleted_count
  );
  
  RETURN deleted_count;
END;
$$;

-- Advanced smart cleanup function: Keeps frequently accessed records longer
CREATE OR REPLACE FUNCTION smart_cache_cleanup(
  max_cache_size_mb INTEGER DEFAULT 100,
  min_age_days INTEGER DEFAULT 7,
  max_age_days INTEGER DEFAULT 30
)
RETURNS INTEGER
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = public
AS $$
DECLARE
  current_size_mb INTEGER;
  deleted_count INTEGER := 0;
  target_reduction_mb INTEGER;
  min_age_interval INTERVAL := (min_age_days || ' days')::INTERVAL;
  max_age_interval INTERVAL := (max_age_days || ' days')::INTERVAL;
BEGIN
  -- Get current cache size in MB
  SELECT COALESCE(SUM(pg_column_size(gemini_response) + pg_column_size(request_data)) / 1024 / 1024, 0)
  INTO current_size_mb
  FROM public.gemini_cache;
  
  -- First pass: Delete all entries older than max_age_days regardless of access count
  DELETE FROM public.gemini_cache
  WHERE created_at < NOW() - max_age_interval
  RETURNING COUNT(*) INTO deleted_count;
  
  -- If we're still over the size limit, do a second pass based on access patterns
  IF current_size_mb > max_cache_size_mb THEN
    target_reduction_mb := current_size_mb - max_cache_size_mb;
    
    -- Delete less frequently accessed entries older than min_age_days
    -- Order by a score combining age and access_count (prioritize keeping frequently accessed items)
    WITH ranked_cache AS (
      SELECT 
        id,
        (access_count::float / EXTRACT(EPOCH FROM (NOW() - created_at)) * 86400) AS access_score,
        pg_column_size(gemini_response) + pg_column_size(request_data) AS entry_size
      FROM public.gemini_cache
      WHERE created_at < NOW() - min_age_interval
      ORDER BY access_score ASC
    ),
    to_delete AS (
      SELECT 
        id,
        SUM(entry_size) OVER (ORDER BY access_score ASC) / 1024 / 1024 AS cumulative_size_mb
      FROM ranked_cache
      WHERE access_score < 5 -- Don't delete very frequently accessed items
    )
    DELETE FROM public.gemini_cache
    WHERE id IN (
      SELECT id FROM to_delete
      WHERE cumulative_size_mb <= target_reduction_mb
    );
    
    GET DIAGNOSTICS deleted_count = ROW_COUNT;
  END IF;
  
  -- Log the cleanup operation
  INSERT INTO public.maintenance_logs (
    operation, 
    details, 
    records_affected
  ) 
  VALUES (
    'smart_cache_cleanup',
    format('Cleaned cache targeting %s MB max size (current: %s MB)', max_cache_size_mb, current_size_mb),
    deleted_count
  );
  
  RETURN deleted_count;
END;
$$;

-- Enable pg_cron extension if not already enabled
-- Note: Requires superuser privileges. You may need to run this directly in the Supabase dashboard
-- CREATE EXTENSION IF NOT EXISTS pg_cron;

-- Schedule the cleanup job (using pg_cron)
-- Note: This is the command you should run in the Supabase SQL editor
/*
SELECT cron.schedule(
  'daily-cache-cleanup',              -- name of the job
  '0 3 * * *',                        -- cron schedule (3 AM UTC daily)
  $$SELECT smart_cache_cleanup(100, 7, 30)$$  -- 100MB max, keep 7-30 days based on usage
);

-- Alternative simpler job if the smart cleanup is too resource-intensive
SELECT cron.schedule(
  'weekly-cache-cleanup',             -- name of the job
  '0 4 * * 0',                        -- cron schedule (4 AM UTC every Sunday)
  $$SELECT cleanup_old_cache('14 days')$$  -- Remove entries older than 14 days
);
*/